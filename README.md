# ğŸ’ª Workout Form Classifier

ML-powered workout form analyzer using fine-tuned CLIP for real-time form feedback and form score reporting.

**Status**: MVP development ğŸš€

---

## ğŸ¯ What It Does

Analyzes gym videos frame-by-frame to detect workout form quality:

- âœ… **Good Form Detection**: Automatically identifies perfect form moments
- âŒ **Bad Form Detection**: Flags form breakdowns with specific issues
- ğŸ“Š **Form Scoring**: 0-100 score per set with actionable feedback
- ğŸ¬ **Video Analysis**: Batch process workout videos or real-time camera feed
- ğŸ“± **Web Dashboard**: Upload videos, get instant form reports

---

## ğŸ“‹ Pipeline Architecture

```
Workout Video
    â†“
[0] Scene Detection      â†’ Detect set boundaries (PySceneDetect)
    â†“
[1] Frame Extraction     â†’ Extract key frames from each set
    â†“
[2] CLIP Classification  â†’ Classify frames (Good vs Bad Form)
    â†“
[3] Filtering & Scoring  â†’ Aggregate scores, detect issues
    â†“
[4] Human Review (opt)   â†’ Preview server for verification
    â†“
[5] Report Generation    â†’ JSON report + recommendations
    â†“
Report Output (JSON/PDF/Web)
```

---

## ğŸ‹ï¸ Supported Exercises (MVP)

- [ ] Squat (good/bad form variants)
- [ ] Deadlift (good/bad form variants)
- [ ] Bench Press (good/bad form variants)
- [ ] Barbell Row (good/bad form variants)
- [ ] Overhead Press (good/bad form variants)

*(Expandable to any exercise - just add training data)*

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repo
git clone https://github.com/odanree/workout-form-classifier
cd workout-form-classifier

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download/train CLIP model (first run)
python scripts/setup_model.py
```

### Usage

```bash
# Analyze a workout video
python src/batch_runner.py "path/to/workout_video.mp4" --exercise squat

# With custom settings
python src/batch_runner.py "workout.mp4" \
  --exercise deadlift \
  --detection_threshold 1.0 \
  --min_scene_length 0.5

# Generate report as JSON
python src/batch_runner.py "workout.mp4" --output json

# Generate report as PDF (with charts)
python src/batch_runner.py "workout.mp4" --output pdf
```

### Output Example

```json
{
  "video": "squat_session.mp4",
  "exercise": "Squat",
  "duration": 342.5,
  "sets": [
    {
      "set_number": 1,
      "reps": 5,
      "form_score": 94,
      "frames_analyzed": 156,
      "good_form_frames": 147,
      "bad_form_frames": 9,
      "issues": [
        {
          "frame": 23,
          "timestamp": "0:15",
          "issue": "Knee valgus - knees caving inward",
          "severity": "medium"
        }
      ]
    }
  ],
  "overall_form_score": 91,
  "recommendations": [
    "Excellent knee alignment consistency - keep current form",
    "Focus on depth - ensure you reach parallel or below",
    "Smooth eccentric - avoid dropping weight quickly"
  ]
}
```

---

## ğŸ“ Project Structure

```
workout-form-classifier/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env.example
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ batch_runner.py               # Main orchestrator
â”‚   â”œâ”€â”€ 0_detect_scenes.py            # Scene detection (PySceneDetect)
â”‚   â”œâ”€â”€ 1_extract_frames.py           # Extract frames from scenes
â”‚   â”œâ”€â”€ 2_classify_frames.py          # CLIP classification
â”‚   â”œâ”€â”€ 3_filter_and_score.py         # Filtering & form scoring
â”‚   â”œâ”€â”€ 4_preview_server.py           # Web preview (http://127.0.0.1:8767)
â”‚   â”œâ”€â”€ 5_generate_report.py          # Report generation
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py                 # Configuration management
â”‚       â”œâ”€â”€ logger.py                 # Logging utilities
â”‚       â”œâ”€â”€ video_processor.py        # FFmpeg wrappers
â”‚       â””â”€â”€ clip_utils.py             # CLIP model utilities
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ clip_finetuned_workout.pt    # Fine-tuned CLIP model (download)
â”‚   â””â”€â”€ exercise_configs.json         # Exercise class definitions
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ training_data/
â”‚   â”‚   â”œâ”€â”€ squat/
â”‚   â”‚   â”‚   â”œâ”€â”€ good_form/            # Good form videos
â”‚   â”‚   â”‚   â””â”€â”€ bad_form/             # Bad form videos
â”‚   â”‚   â”œâ”€â”€ deadlift/
â”‚   â”‚   â”œâ”€â”€ bench_press/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ labeled_frames/               # Frame annotations for training
â”‚   â”‚   â”œâ”€â”€ squat_good_form.csv
â”‚   â”‚   â””â”€â”€ squat_bad_form.csv
â”‚   â”‚
â”‚   â””â”€â”€ sample_videos/                # Demo videos
â”‚       â”œâ”€â”€ squat_demo.mp4
â”‚       â””â”€â”€ deadlift_demo.mp4
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_model.py                # Download/initialize CLIP model
â”‚   â”œâ”€â”€ collect_training_data.py      # Video collection helper
â”‚   â”œâ”€â”€ label_frames.py               # Label extracted frames
â”‚   â”œâ”€â”€ finetune_clip.py              # Train fine-tuned CLIP model
â”‚   â”œâ”€â”€ evaluate_model.py             # Model evaluation metrics
â”‚   â””â”€â”€ generate_dummy_data.py        # Create test data
â”‚
â”œâ”€â”€ web/                              # React/Next.js frontend
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ index.js                  # Landing page
â”‚   â”‚   â”œâ”€â”€ upload.js                 # Video upload page
â”‚   â”‚   â””â”€â”€ report.js                 # Form report viewer
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ VideoUploader.js
â”‚   â”‚   â”œâ”€â”€ FormScoreCard.js
â”‚   â”‚   â”œâ”€â”€ SetDetailCard.js
â”‚   â”‚   â””â”€â”€ RecommendationList.js
â”‚   â””â”€â”€ styles/
â”‚       â””â”€â”€ globals.css
â”‚
â”œâ”€â”€ backend/                          # FastAPI backend
â”‚   â”œâ”€â”€ main.py                       # API server
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ upload.py                 # Video upload endpoint
â”‚   â”‚   â”œâ”€â”€ analyze.py                # Analysis endpoint
â”‚   â”‚   â””â”€â”€ report.py                 # Report retrieval
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â””â”€â”€ process_video.py          # Celery task for video processing
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ schemas.py                # Pydantic schemas
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_scene_detection.py
â”‚   â”œâ”€â”€ test_clip_classification.py
â”‚   â”œâ”€â”€ test_form_scoring.py
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ SETUP.md                      # Detailed setup instructions
â”‚   â”œâ”€â”€ TRAINING.md                   # How to train custom models
â”‚   â”œâ”€â”€ DATA_COLLECTION.md            # Data collection guide
â”‚   â”œâ”€â”€ ARCHITECTURE.md               # Technical deep-dive
â”‚   â””â”€â”€ API_REFERENCE.md              # API documentation
â”‚
â””â”€â”€ config/
    â”œâ”€â”€ workflow_config.json          # Pipeline configuration
    â”œâ”€â”€ exercise_definitions.json     # Exercise class descriptions
    â””â”€â”€ form_feedback.json            # Form issue templates
```

---

## ğŸ§  How Form Classification Works

### Fine-Tuned CLIP Model

We train CLIP on pairs of images + descriptions:

```python
# Training data example
{
  "image": "squat_frame_001.jpg",
  "description": "perfect squat form with knees tracking over toes chest up neutral spine full depth",
  "label": "good_form"
}

{
  "image": "squat_frame_042.jpg",
  "description": "poor squat form with knees caving inward valgus chest collapsed rounded back shallow depth",
  "label": "bad_form"
}
```

CLIP then generalizes to new workout videos, scoring form quality per frame.

### Classification Pipeline

1. **Scene Detection** â†’ Identifies set boundaries (rest periods = scene changes)
2. **Frame Extraction** â†’ Sample frames during active lifting (skip pauses)
3. **CLIP Scoring** â†’ Score each frame (0-100 form quality)
4. **Aggregation** â†’ Per-set form score via majority voting
5. **Issue Detection** â†’ Flag frames where form broke down

---

## ğŸ“Š MVP Features

- [x] Repo structure with clear separation of concerns
- [ ] Scene detection (PySceneDetect integration)
- [ ] Frame extraction pipeline
- [ ] CLIP fine-tuning on squat data
- [ ] Form classification (good vs bad)
- [ ] Form scoring algorithm
- [ ] Web preview server
- [ ] Report generation (JSON â†’ PDF)
- [ ] Web dashboard (React)
- [ ] API backend (FastAPI)
- [ ] Celery task queue for background processing

---

## ğŸ”§ Technologies

- **ML**: PyTorch, Hugging Face Transformers (CLIP)
- **Video**: OpenCV, FFmpeg, PySceneDetect
- **Backend**: FastAPI, Celery, Redis
- **Frontend**: React/Next.js, TypeScript
- **Deploy**: Docker, Vercel (frontend), Railway/Render (backend)

---

## ğŸ“ˆ Roadmap

### Phase 1 (MVP) - 2-3 weeks
- âœ… Repo structure
- [ ] Squat form classification (good/bad)
- [ ] Web upload + report generation
- [ ] Form scoring algorithm

### Phase 2 - 1-2 months
- [ ] Support 5 exercises (squat, deadlift, bench, row, OHP)
- [ ] Real-time camera feed processing
- [ ] Advanced form issue detection (granular feedback)
- [ ] User dashboard with workout history

### Phase 3 - Launch
- [ ] Mobile app (React Native)
- [ ] Gym API integrations
- [ ] Personal trainer dashboard
- [ ] SaaS pricing model

---

## ğŸš€ Deployment

### Local Development
```bash
# Terminal 1: Backend
cd backend
uvicorn main:app --reload

# Terminal 2: Frontend
cd web
npm run dev

# Terminal 3: Celery worker (optional)
celery -A tasks worker --loglevel=info
```

### Production (Vercel + Railway)
```bash
# Deploy frontend to Vercel
vercel deploy

# Deploy backend to Railway
railway up
```

---

## ğŸ“š Documentation

See `docs/` folder for:
- **SETUP.md** - Installation & configuration
- **TRAINING.md** - How to fine-tune CLIP on your own data
- **DATA_COLLECTION.md** - Strategies for collecting labeled video data
- **ARCHITECTURE.md** - Technical deep-dive into the pipeline
- **API_REFERENCE.md** - Full API documentation

---

## ğŸ’¡ Use Cases

1. **Personal Training App** - Coach reviews form automatically
2. **Gym Memberships** - Mirror/tablet feedback during workouts
3. **Fitness Influencers** - Auto-generate form breakdown content
4. **Physical Therapy** - Monitor rehabilitation exercise form
5. **Sports Teams** - Strength & conditioning performance analysis

---

## ğŸ¤ Contributing

Contributions welcome! Areas to help:

- [ ] Collect labeled training data for each exercise
- [ ] Build web UI components
- [ ] Optimize CLIP inference speed
- [ ] Add more exercises
- [ ] Write tests

---

## ğŸ“ License

MIT - Feel free to use for your projects!

---

## ğŸ¯ Next Steps

1. **Setup**: Follow [SETUP.md](docs/SETUP.md)
2. **Collect Data**: Use [DATA_COLLECTION.md](docs/DATA_COLLECTION.md) for training data strategy
3. **Train Model**: Run `scripts/finetune_clip.py`
4. **Test Pipeline**: `python src/batch_runner.py sample_videos/squat_demo.mp4`
5. **Build Web UI**: Contribute to `web/` folder
6. **Deploy**: Push to Vercel + Railway

---

**Built with â¤ï¸ by Danh Le**  
Portfolio: [danhle.net](https://danhle.net)  
GitHub: [@odanree](https://github.com/odanree)
